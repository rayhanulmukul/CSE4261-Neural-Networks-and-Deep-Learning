{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f81cb7",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e13f34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd301e",
   "metadata": {},
   "source": [
    "# Load and preprocess MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a483c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340aa9f6",
   "metadata": {},
   "source": [
    "# Build a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c12fc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input = Input(shape=(28, 28, 1))\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91c3f2",
   "metadata": {},
   "source": [
    "# Custom training using tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad8ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_tape():\n",
    "    model = create_model()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        print(f\"Epoch {epoch+1}/5\")\n",
    "        acc_metric.reset_state()\n",
    "        for i in range(0, len(x_train), 32):\n",
    "            x_batch = x_train[i:i+32]\n",
    "            y_batch = y_train[i:i+32]  # Already one-hot\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x_batch, training=True)\n",
    "                loss = loss_fn(y_batch, logits)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            acc_metric.update_state(y_batch, logits)\n",
    "        print(f\"Train accuracy: {acc_metric.result().numpy():.4f}\")\n",
    "    end = time.time()\n",
    "\n",
    "    # Test accuracy\n",
    "    logits_test = model(x_test, training=False)\n",
    "    test_acc = tf.keras.metrics.categorical_accuracy(y_test, logits_test)\n",
    "    final_acc = tf.reduce_mean(test_acc).numpy()\n",
    "\n",
    "    return final_acc, end - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b6e5e",
   "metadata": {},
   "source": [
    "# Training using model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbcc9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_fit():\n",
    "    model = create_model()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
    "    end = time.time()\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test accuracy (fit):\", test_acc)\n",
    "    return test_acc, end - start    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1829d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayhanul/.local/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:675: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9253\n",
      "Epoch 2/5\n",
      "Train accuracy: 0.9668\n",
      "Epoch 3/5\n",
      "Train accuracy: 0.9775\n",
      "Epoch 4/5\n",
      "Train accuracy: 0.9834\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "acc_tape, time_tape = train_with_tape()\n",
    "acc_fit, time_fit = train_with_fit()\n",
    "\n",
    "\n",
    "print(\"\\n Final Comparison:\")\n",
    "print(f\"tf.GradientTape(): Accuracy = {acc_tape:.4f}, Time = {time_tape:.2f} sec\")\n",
    "print(f\"model.fit():       Accuracy = {acc_fit:.4f}, Time = {time_fit:.2f} sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
